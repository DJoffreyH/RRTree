2025-07-25 18:09:42,715 - INFO - Creating container for sympy__sympy-24102...
2025-07-25 18:09:42,920 - INFO - Container for sympy__sympy-24102 created: 2fbc950c53e0df9f6214327d83b9975e438d255f46baddc8dc8e2a7404517a43
2025-07-25 18:09:43,084 - INFO - Container for sympy__sympy-24102 started: 2fbc950c53e0df9f6214327d83b9975e438d255f46baddc8dc8e2a7404517a43
2025-07-25 18:09:43,084 - INFO - Intermediate patch for sympy__sympy-24102 written to logs/run_evaluation/batch_30/gold/sympy__sympy-24102/patch.diff, now applying to container...
2025-07-25 18:09:43,253 - INFO - >>>>> Applied Patch:
Checking patch sympy/parsing/mathematica.py...
Applied patch sympy/parsing/mathematica.py cleanly.

2025-07-25 18:09:44,019 - INFO - Git diff before:
diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py
index 7ea14ce33a..7bfd5e4bb4 100644
--- a/sympy/parsing/mathematica.py
+++ b/sympy/parsing/mathematica.py
@@ -654,7 +654,7 @@ def _from_mathematica_to_tokens(self, code: str):
             code_splits[i] = code_split
 
         # Tokenize the input strings with a regular expression:
-        token_lists = [tokenizer.findall(i) if isinstance(i, str) else [i] for i in code_splits]
+        token_lists = [tokenizer.findall(i) if isinstance(i, str) and i.isascii() else [i] for i in code_splits]
         tokens = [j for i in token_lists for j in i]
 
         # Remove newlines at the beginning
2025-07-25 18:09:44,019 - INFO - Eval script for sympy__sympy-24102 written to logs/run_evaluation/batch_30/gold/sympy__sympy-24102/eval.sh; copying to container...
2025-07-25 18:09:51,982 - INFO - Test runtime: 7.90 seconds
2025-07-25 18:09:51,982 - INFO - Test output for sympy__sympy-24102 written to logs/run_evaluation/batch_30/gold/sympy__sympy-24102/test_output.txt
2025-07-25 18:09:52,067 - INFO - Git diff after:
diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py
index 7ea14ce33a..7bfd5e4bb4 100644
--- a/sympy/parsing/mathematica.py
+++ b/sympy/parsing/mathematica.py
@@ -654,7 +654,7 @@ def _from_mathematica_to_tokens(self, code: str):
             code_splits[i] = code_split
 
         # Tokenize the input strings with a regular expression:
-        token_lists = [tokenizer.findall(i) if isinstance(i, str) else [i] for i in code_splits]
+        token_lists = [tokenizer.findall(i) if isinstance(i, str) and i.isascii() else [i] for i in code_splits]
         tokens = [j for i in token_lists for j in i]
 
         # Remove newlines at the beginning
2025-07-25 18:09:52,067 - INFO - Grading answer for sympy__sympy-24102...
2025-07-25 18:09:52,068 - INFO - report: {'sympy__sympy-24102': {'patch_is_None': False, 'patch_exists': True, 'patch_successfully_applied': True, 'resolved': True, 'tests_status': {'FAIL_TO_PASS': {'success': ['test_mathematica', 'test_parser_mathematica_tokenizer'], 'failure': []}, 'PASS_TO_PASS': {'success': [], 'failure': []}, 'FAIL_TO_FAIL': {'success': [], 'failure': []}, 'PASS_TO_FAIL': {'success': [], 'failure': []}}}}
Result for sympy__sympy-24102: resolved: True
2025-07-25 18:09:52,068 - INFO - Attempting to stop container sweb.eval.sympy__sympy-24102.batch_30...
2025-07-25 18:10:07,315 - INFO - Attempting to remove container sweb.eval.sympy__sympy-24102.batch_30...
2025-07-25 18:10:07,335 - INFO - Container sweb.eval.sympy__sympy-24102.batch_30 removed.
2025-07-25 18:10:07,335 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.sympy_1776_sympy-24102:latest...
2025-07-25 18:10:07,413 - INFO - Image swebench/sweb.eval.x86_64.sympy_1776_sympy-24102:latest removed.
